{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019_12_20_Fri_LSTM_tagging.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marofmar/TIL/blob/master/2019_12_20_Fri_LSTM_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhtXpMpP1m2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvcanFOF2Trr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a429db39-0604-4177-a644-12295990a3ff"
      },
      "source": [
        "training_data = [\n",
        "                 ('I am a boy'.lower().split(), ['N','V','D','N']),\n",
        "                 ('You are a girl'.lower().split(), ['N', 'V','D','N']),\n",
        "                 ('He loves elephants'.lower().split(), ['N', 'V', 'N']),\n",
        "                 ('Jacky wears a glasses'.lower().split(), ['N','V','D','N']),\n",
        "                 ('The cat loves fish'.lower().split(), ['D','N','V','N'])\n",
        "]\n",
        "# N for noun, V for verb, D for Determinants? like the or a/an\n",
        "tag2idx = {'D':0, 'N':1, 'V':2}\n",
        "word2idx = {}\n",
        "for sentence, tags in training_data:\n",
        "    for word in sentence:\n",
        "        if word not in word2idx:\n",
        "            word2idx[word] = len(word2idx)\n",
        "print(word2idx)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'i': 0, 'am': 1, 'a': 2, 'boy': 3, 'you': 4, 'are': 5, 'girl': 6, 'he': 7, 'loves': 8, 'elephants': 9, 'jacky': 10, 'wears': 11, 'glasses': 12, 'the': 13, 'cat': 14, 'fish': 15}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC_G8A5w3mGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_seq(sentence, dic):\n",
        "    idxs = [dic[w] for w in sentence]\n",
        "    idxs = np.array(idxs)\n",
        "    return torch.from_numpy(idxs)\n",
        "\n",
        "# will be used to both sentences and tags to change the words into numbers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrHMd3b64N4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim) \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim) \n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size) \n",
        "        self.hidden = self.init_hidden() \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1,1,self.hidden_dim),\n",
        "                torch.zeros(1,1,self.hidden_dim))\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence) \n",
        "        lstm_out, self.hidden = self.lstm(embeds.view(len(sentence), 1, -1), self.hidden) \n",
        "        tag_outputs = self.hidden2tag(lstm_out.view(len(sentence), -1)) \n",
        "        tag_scores = F.log_softmax(tag_outputs, dim = 1) \n",
        "        return tag_scores \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY1E4pZc9VhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set params for training\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), len(tag2idx)) \n",
        "\n",
        "loss_function = nn.NLLLoss() \n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL7bFiLq9rrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "aa3b59f3-fcd7-4348-9220-955e768223b2"
      },
      "source": [
        "n_epochs = 500\n",
        "for i in range(n_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    for sentence, tags in training_data:\n",
        "        model.zero_grad()\n",
        "        model.hidden = model.init_hidden() \n",
        "        inputs = prepare_seq(sentence, word2idx)\n",
        "        target = prepare_seq(tags, tag2idx) \n",
        "        pred = model(inputs)\n",
        "        loss = loss_function(pred, target) \n",
        "        epoch_loss += loss.item() \n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "    if (i%20==19):\n",
        "        print(\"Epoch: %d, Loss: %1.5f\" %(i+1, epoch_loss/len(training_data)))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20, Loss: 0.72428\n",
            "Epoch: 40, Loss: 0.69491\n",
            "Epoch: 60, Loss: 0.66565\n",
            "Epoch: 80, Loss: 0.63657\n",
            "Epoch: 100, Loss: 0.60757\n",
            "Epoch: 120, Loss: 0.57847\n",
            "Epoch: 140, Loss: 0.54906\n",
            "Epoch: 160, Loss: 0.51919\n",
            "Epoch: 180, Loss: 0.48876\n",
            "Epoch: 200, Loss: 0.45778\n",
            "Epoch: 220, Loss: 0.42636\n",
            "Epoch: 240, Loss: 0.39470\n",
            "Epoch: 260, Loss: 0.36314\n",
            "Epoch: 280, Loss: 0.33211\n",
            "Epoch: 300, Loss: 0.30218\n",
            "Epoch: 320, Loss: 0.27392\n",
            "Epoch: 340, Loss: 0.24780\n",
            "Epoch: 360, Loss: 0.22412\n",
            "Epoch: 380, Loss: 0.20297\n",
            "Epoch: 400, Loss: 0.18428\n",
            "Epoch: 420, Loss: 0.16786\n",
            "Epoch: 440, Loss: 0.15348\n",
            "Epoch: 460, Loss: 0.14090\n",
            "Epoch: 480, Loss: 0.12986\n",
            "Epoch: 500, Loss: 0.12016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heUgemlaC5cH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ef15d0f3-38f8-497a-9589-f96ee755c56e"
      },
      "source": [
        "test_sentence = 'I am the girl'.lower().split()\n",
        "inputs = prepare_seq(test_sentence, word2idx) \n",
        "tag_scores = model(inputs)\n",
        "\n",
        "_, predicted = torch.max(tag_scores, 1)\n",
        "print(tag_scores , predicted)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-3.3181, -0.5852, -0.8995],\n",
            "        [-2.9943, -1.9148, -0.2200],\n",
            "        [-0.1783, -2.6058, -2.4142],\n",
            "        [-3.5550, -0.1299, -2.3728]], grad_fn=<LogSoftmaxBackward>) tensor([1, 2, 0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9jNHrF_FdUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}